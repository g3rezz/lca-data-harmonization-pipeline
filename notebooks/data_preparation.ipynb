{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covert ILCD HTML files to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: EPD_DataSet.html\n",
      "Headers: ['Field Name (de)', 'Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (de)', 'Definition (en)', 'Original ILCD Format Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\EPD_DataSet.csv\n",
      "Processing: EPD_FlowDataSet.html\n",
      "Headers: ['Field Name (de)', 'Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (de)', 'Definition (en)', 'Original ILCD Format Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\EPD_FlowDataSet.csv\n",
      "Processing: ILCD_Common_DataTypes.html\n",
      "Headers: ['Data Type', 'Base Type', 'Description']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_Common_DataTypes.csv\n",
      "Processing: ILCD_Common_EnumerationValues.html\n",
      "Headers: ['List name', 'Value', 'Definition (en)']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_Common_EnumerationValues.csv\n",
      "Processing: ILCD_ContactDataSet.html\n",
      "Headers: ['Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_ContactDataSet.csv\n",
      "Processing: ILCD_FlowPropertyDataSet.html\n",
      "Headers: ['Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_FlowPropertyDataSet.csv\n",
      "Processing: ILCD_LCIAMethodDataSet.html\n",
      "Headers: ['Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_LCIAMethodDataSet.csv\n",
      "Processing: ILCD_SourceDataSet.html\n",
      "Headers: ['Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_SourceDataSet.csv\n",
      "Processing: ILCD_UnitGroupDataSet.html\n",
      "Headers: ['Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_UnitGroupDataSet.csv\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def parse_table_with_rowspan(table):\n",
    "    \"\"\"\n",
    "    Parse an HTML table into a grid (list of lists) taking into account cells\n",
    "    with rowspan (and colspan). For each cell with a rowspan, its value is\n",
    "    inserted in subsequent rows.\n",
    "    \"\"\"\n",
    "    rows = table.find_all(\"tr\")\n",
    "    grid = []\n",
    "    spanning = {}  # key: (row_index, col_index) -> cell text\n",
    "    for i, row in enumerate(rows):\n",
    "        cells = []\n",
    "        col = 0\n",
    "        # Process each cell (td or th)\n",
    "        for cell in row.find_all([\"td\", \"th\"]):\n",
    "            # Fill in any spanning cells that belong in this row and position\n",
    "            while (i, col) in spanning:\n",
    "                cells.append(spanning[(i, col)])\n",
    "                del spanning[(i, col)]\n",
    "                col += 1\n",
    "            # Get cell text (cleaned up)\n",
    "            cell_text = \" \".join(cell.get_text(strip=True).split())\n",
    "            # Determine rowspan and colspan (default 1)\n",
    "            try:\n",
    "                rowspan = int(cell.get(\"rowspan\", \"1\"))\n",
    "            except:\n",
    "                rowspan = 1\n",
    "            try:\n",
    "                colspan = int(cell.get(\"colspan\", \"1\"))\n",
    "            except:\n",
    "                colspan = 1\n",
    "\n",
    "            # Add current cell text for current cell and for additional columns (if any)\n",
    "            cells.append(cell_text)\n",
    "            # Mark spanning cells for subsequent rows\n",
    "            if rowspan > 1:\n",
    "                for r in range(1, rowspan):\n",
    "                    for c in range(col, col + colspan):\n",
    "                        spanning[(i + r, c)] = cell_text\n",
    "            col += colspan\n",
    "        # If there are still spanning cells for positions at the end, add them.\n",
    "        while (i, col) in spanning:\n",
    "            cells.append(spanning[(i, col)])\n",
    "            del spanning[(i, col)]\n",
    "            col += 1\n",
    "        grid.append(cells)\n",
    "    return grid\n",
    "\n",
    "# Directories for HTML and CSV files\n",
    "html_directory = \"../data/pipeline1/html\"\n",
    "output_directory = \"../data/pipeline1/csv\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Mapping of inconsistent headers to standardized headers (if needed)\n",
    "header_mapping = {\n",
    "    \"Field name\": \"Field Name (en)\",\n",
    "    \"Field name (de)\": \"Field Name (de)\",\n",
    "    \"Field name (en)\": \"Field Name (en)\",\n",
    "    \"Element/Attribute name\": \"Element/Attribute Name\",\n",
    "    \"Element/attribute name\": \"Element/Attribute Name\",\n",
    "    \"Data type\": \"Datatype\",\n",
    "    \"Definition\": \"Definition (en)\",\n",
    "}\n",
    "\n",
    "for file_name in os.listdir(html_directory):\n",
    "    if file_name.endswith(\".html\"):\n",
    "        html_file_path = os.path.join(html_directory, file_name)\n",
    "        csv_file_name = os.path.splitext(file_name)[0] + \".csv\"\n",
    "        csv_output_path = os.path.join(output_directory, csv_file_name)\n",
    "\n",
    "        print(f\"Processing: {file_name}\")\n",
    "\n",
    "        # Load the HTML content\n",
    "        with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "\n",
    "        # Parse the HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "        # Special handling for ILCD_Common_EnumerationValues.html\n",
    "        if file_name == \"ILCD_Common_EnumerationValues.html\":\n",
    "            # For this file, we assume the table to process is the first table\n",
    "            table = soup.find(\"table\")\n",
    "            if not table:\n",
    "                print(f\"No table found in {file_name}. Skipping.\")\n",
    "                continue\n",
    "            # Parse the table into a grid (list of rows with expanded rowspans)\n",
    "            grid = parse_table_with_rowspan(table)\n",
    "            # Assume the first row is the header row\n",
    "            headers = grid[0]\n",
    "            # Apply header mapping if available\n",
    "            headers = [header_mapping.get(h, h) for h in headers]\n",
    "            data_rows = grid[1:]\n",
    "            df = pd.DataFrame(data_rows, columns=headers)\n",
    "        else:\n",
    "            # For all other files, use your existing logic\n",
    "            table = soup.find(\"table\", {\"id\": \"tableID\"})\n",
    "            if not table:\n",
    "                print(f\"No table with id 'tableID' found in {file_name}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            headers = [\n",
    "                header_mapping.get(th.get_text(strip=True), th.get_text(strip=True))\n",
    "                for th in table.find_all(\"th\")\n",
    "            ]\n",
    "            rows = []\n",
    "            for tr in table.find_all(\"tr\"):\n",
    "                row = []\n",
    "                for td in tr.find_all(\"td\"):\n",
    "                    # Remove elements with class \"info\"\n",
    "                    for info_element in td.find_all(class_=\"info\"):\n",
    "                        info_element.extract()\n",
    "                    # If an <a> tag exists, extract only its text; otherwise, full cell text\n",
    "                    first_link = td.find(\"a\")\n",
    "                    if first_link:\n",
    "                        cleaned_text = first_link.get_text(strip=True)\n",
    "                    else:\n",
    "                        cleaned_text = \" \".join(td.get_text(strip=True).split())\n",
    "                    row.append(cleaned_text)\n",
    "                rows.append(row)\n",
    "\n",
    "            max_columns = max(len(row) for row in rows)\n",
    "            adjusted_rows = [row + [\"\"] * (max_columns - len(row)) for row in rows]\n",
    "            adjusted_headers = headers + [\"\"] * (max_columns - len(headers))\n",
    "            df = pd.DataFrame(adjusted_rows, columns=adjusted_headers)\n",
    "\n",
    "        # Clean empty cells (whitespace only becomes NaN), drop empty rows/columns\n",
    "        df.replace(r\"^\\s*$\", pd.NA, regex=True, inplace=True)\n",
    "        df = df.dropna(axis=1, how=\"all\")\n",
    "        df = df.dropna(axis=0, how=\"all\")\n",
    "\n",
    "        # Save the DataFrame to CSV\n",
    "        df.to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n",
    "        print(f\"Saved: {csv_output_path}\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epub_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
