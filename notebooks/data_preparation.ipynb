{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covert ILCD HTML files to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: EPD_DataSet.html\n",
      "Headers: ['Field Name (de)', 'Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (de)', 'Definition (en)', 'Original ILCD Format Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\EPD_DataSet.csv\n",
      "Processing: EPD_FlowDataSet.html\n",
      "Headers: ['Field Name (de)', 'Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (de)', 'Definition (en)', 'Original ILCD Format Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\EPD_FlowDataSet.csv\n",
      "Processing: ILCD_Common_DataTypes.html\n",
      "Headers: ['Data Type', 'Base Type', 'Description']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_Common_DataTypes.csv\n",
      "Processing: ILCD_Common_EnumerationValues.html\n",
      "Headers: ['List name', 'Value', 'Definition (en)']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_Common_EnumerationValues.csv\n",
      "Processing: ILCD_ContactDataSet.html\n",
      "Headers: ['Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_ContactDataSet.csv\n",
      "Processing: ILCD_FlowPropertyDataSet.html\n",
      "Headers: ['Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_FlowPropertyDataSet.csv\n",
      "Processing: ILCD_LCIAMethodDataSet.html\n",
      "Headers: ['Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_LCIAMethodDataSet.csv\n",
      "Processing: ILCD_SourceDataSet.html\n",
      "Headers: ['Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_SourceDataSet.csv\n",
      "Processing: ILCD_UnitGroupDataSet.html\n",
      "Headers: ['Field Name (en)', 'Element/Attribute Name', 'Requ.', 'Occ.', 'Datatype', 'Definition (en)', 'eDoc ID']\n",
      "Saved: ../data/pipeline1/csv\\ILCD_UnitGroupDataSet.csv\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing the HTML files\n",
    "html_directory = \"../data/pipeline1/html\"\n",
    "output_directory = \"../data/pipeline1/csv\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Mapping of inconsistent headers to standardized headers\n",
    "header_mapping = {\n",
    "    \"Field name\": \"Field Name (en)\",\n",
    "    \"Field name (de)\": \"Field Name (de)\",\n",
    "    \"Field name (en)\": \"Field Name (en)\",\n",
    "    \"Element/Attribute name\": \"Element/Attribute Name\",\n",
    "    \"Element/attribute name\": \"Element/Attribute Name\",\n",
    "    \"Data type\": \"Datatype\",\n",
    "    \"Definition\": \"Definition (en)\",\n",
    "}\n",
    "\n",
    "# Loop through all HTML files in the directory\n",
    "for file_name in os.listdir(html_directory):\n",
    "    if file_name.endswith(\".html\"):\n",
    "        html_file_path = os.path.join(html_directory, file_name)\n",
    "        csv_file_name = os.path.splitext(file_name)[0] + \".csv\"\n",
    "        csv_output_path = os.path.join(output_directory, csv_file_name)\n",
    "\n",
    "        print(f\"Processing: {file_name}\")\n",
    "\n",
    "        # Load the HTML content\n",
    "        with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "\n",
    "        # Parse the HTML content with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "        # Find the table by its ID (adjust if necessary for your files)\n",
    "        table = soup.find(\"table\", {\"id\": \"tableID\"})\n",
    "        if not table:\n",
    "            print(f\"No table with id 'tableID' found in {file_name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Extract headers and rows from the table\n",
    "        headers = [\n",
    "            header_mapping.get(th.get_text(strip=True), th.get_text(strip=True))\n",
    "            for th in table.find_all(\"th\")\n",
    "        ]\n",
    "        rows = []\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            row = []\n",
    "            for td in tr.find_all(\"td\"):\n",
    "                # Remove elements with class \"info\"\n",
    "                for info_element in td.find_all(class_=\"info\"):\n",
    "                    info_element.extract()\n",
    "\n",
    "                # If an <a> tag exists, extract only its text\n",
    "                first_link = td.find(\"a\")\n",
    "                if first_link:\n",
    "                    cleaned_text = first_link.get_text(strip=True)\n",
    "                else:\n",
    "                    cleaned_text = \" \".join(td.get_text(strip=True).split())\n",
    "                row.append(cleaned_text)\n",
    "            rows.append(row)\n",
    "\n",
    "        print(\"Headers:\", headers)\n",
    "\n",
    "        # Ensure consistent column length\n",
    "        max_columns = max(len(row) for row in rows)\n",
    "        adjusted_rows = [row + [\"\"] * (max_columns - len(row)) for row in rows]\n",
    "        adjusted_headers = headers + [\"\"] * (max_columns - len(headers))\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(adjusted_rows, columns=adjusted_headers)\n",
    "\n",
    "        # Clean empty cells by replacing whitespace-only entries with NaN\n",
    "        df.replace(r\"^\\s*$\", pd.NA, regex=True, inplace=True)\n",
    "\n",
    "        # Drop columns with all empty values\n",
    "        df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "        # Drop rows with all empty values\n",
    "        df = df.dropna(axis=0, how=\"all\")\n",
    "\n",
    "        # Save the cleaned DataFrame as CSV\n",
    "        df.to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "        print(f\"Saved: {csv_output_path}\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epub_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
