{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Missing column 'Field Name (de)' in ../data/csv/ILCD_FlowPropertyDataSet.csv. Skipping this file.\n",
      "Warning: Missing column 'Definition (de)' in ../data/csv/ILCD_FlowPropertyDataSet.csv. Skipping this file.\n",
      "Warning: Missing column 'Original ILCD Format Definition (en)' in ../data/csv/ILCD_FlowPropertyDataSet.csv. Skipping this file.\n",
      "Warning: Missing column 'Field Name (de)' in ../data/csv/ILCD_LCIAMethodDataSet.csv. Skipping this file.\n",
      "Warning: Missing column 'Definition (de)' in ../data/csv/ILCD_LCIAMethodDataSet.csv. Skipping this file.\n",
      "Warning: Missing column 'Original ILCD Format Definition (en)' in ../data/csv/ILCD_LCIAMethodDataSet.csv. Skipping this file.\n",
      "Vector store saved to ../embeddings/bge-m3_csv_faiss_index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "\n",
    "def load_and_store(csv_paths, vectorstore_path):\n",
    "    documents = []\n",
    "\n",
    "    # Process each CSV\n",
    "    for csv_path in csv_paths:\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Check for required columns and handle missing columns gracefully\n",
    "        required_columns = [\n",
    "            \"Field Name (de)\",\n",
    "            \"Field Name (en)\",\n",
    "            \"Element/Attribute Name\",\n",
    "            \"Datatype\",\n",
    "            \"Definition (de)\",\n",
    "            \"Definition (en)\",\n",
    "            \"Original ILCD Format Definition (en)\",\n",
    "        ]\n",
    "        for column in required_columns:\n",
    "            if column not in df.columns:\n",
    "                print(\n",
    "                    f\"Warning: Missing column '{column}' in {csv_path}. Skipping this file.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "        # Add schema_type based on file name\n",
    "        schema_type = csv_path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            content = (\n",
    "                f\"'{row.get('Field Name (de)', '')}',\"\n",
    "                f\"'{row.get('Field Name (en)', '')}',\"\n",
    "                f\"'{row.get('Element/Attribute Name', '')}',\"\n",
    "                f\"'{row.get('Datatype', '')}',\"\n",
    "                f\"'{row.get('Definition (de)', '')}',\"\n",
    "                f\"'{row.get('Definition (en)', '')}',\"\n",
    "                f\"'{row.get('Original ILCD Format Definition (en)', '')}'\"\n",
    "            )\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content=content.strip(),\n",
    "                    metadata={\"source\": csv_path, \"schema_type\": schema_type},\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Split into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=0)\n",
    "    all_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Write the split chunks to a text file with metadata\n",
    "    with open(\"../data/chunks/all_chunks_output_csv.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        for i, chunk in enumerate(all_splits):\n",
    "            file.write(f\"Chunk {i+1}:\\n\")\n",
    "            file.write(chunk.page_content + \"\\n\")\n",
    "            file.write(\"Metadata:\\n\")\n",
    "            file.write(str(chunk.metadata) + \"\\n\")\n",
    "            file.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "    # Create and save FAISS vector store\n",
    "    embeddings = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    vectorstore = FAISS.from_documents(all_splits, embedding=embeddings)\n",
    "    vectorstore.save_local(vectorstore_path)\n",
    "    print(f\"Vector store saved to {vectorstore_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage with schema-specific CSV files\n",
    "    csv_files = [\n",
    "        \"../data/csv/EPD_DataSet.csv\",\n",
    "        \"../data/csv/EPD_FlowDataSet.csv\",\n",
    "        \"../data/csv/ILCD_FlowPropertyDataSet.csv\",\n",
    "        \"../data/csv/ILCD_LCIAMethodDataSet.csv\",\n",
    "    ]\n",
    "    vectorstore_dir = \"../embeddings/bge-m3_csv_faiss_index\"\n",
    "    load_and_store(csv_files, vectorstore_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
