{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Attribute at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "# Define attribute-schema mapping\n",
    "attribute_schema_mapping = {\n",
    "    \"EPD_DataSet\": [\n",
    "        \"UUID\",\n",
    "        \"Version\",\n",
    "        \"Name (de)\",\n",
    "        \"Name (en)\",\n",
    "        \"Kategorie (original)\",\n",
    "        \"Kategorie (en)\",\n",
    "        \"Konformität\",\n",
    "        \"Laenderkennung\",\n",
    "        \"Typ\",\n",
    "        \"Referenzjahr\",\n",
    "        \"Gueltig bis\",\n",
    "        \"URL\",\n",
    "        \"Declaration owner\",\n",
    "        \"Veroeffentlicht am\",\n",
    "        \"Registrierungsnummer\",\n",
    "        \"Registrierungsstelle\",\n",
    "        \"UUID des Vorgängers\",\n",
    "        \"Version des Vorgängers\",\n",
    "        \"URL des Vorgängers\",\n",
    "        \"Modul\",\n",
    "        \"Szenario\",\n",
    "        \"Szenariobeschreibung\",\n",
    "    ],\n",
    "    # \"EPD_FlowDataSet\": [\n",
    "    #     \"PERE\",\n",
    "    #     \"PERM\",\n",
    "    #     \"PERT\",\n",
    "    #     \"PENRE\",\n",
    "    #     \"PENRM\",\n",
    "    #     \"PENRT\",\n",
    "    #     \"SM\",\n",
    "    #     \"RSF\",\n",
    "    #     \"NRSF\",\n",
    "    #     \"FW\",\n",
    "    #     \"HWD\",\n",
    "    #     \"NHWD\",\n",
    "    #     \"RWD\",\n",
    "    #     \"CRU\",\n",
    "    #     \"MFR\",\n",
    "    #     \"MER\",\n",
    "    #     \"EEE\",\n",
    "    #     \"EET\",\n",
    "    # ],\n",
    "    # \"ILCD_FlowPropertyDataSet\": [\n",
    "    #     \"Bezugsgroesse\",\n",
    "    #     \"Bezugseinheit\",\n",
    "    #     \"Referenzfluss-UUID\",\n",
    "    #     \"Referenzfluss-Name\",\n",
    "    #     \"Schuettdichte (kg/m3)\",\n",
    "    #     \"Flaechengewicht (kg/m2)\",\n",
    "    #     \"Rohdichte (kg/m3)\",\n",
    "    #     \"Schichtdicke (m)\",\n",
    "    #     \"Ergiebigkeit (m2)\",\n",
    "    #     \"Laengengewicht (kg/m)\",\n",
    "    #     \"Stueckgewicht (kg)\",\n",
    "    #     \"Umrechungsfaktor auf 1kg\",\n",
    "    #     \"biogener Kohlenstoffgehalt in kg\",\n",
    "    #     \"biogener Kohlenstoffgehalt (Verpackung) in kg\",\n",
    "    # ],\n",
    "    # \"ILCD_LCIAMethodDataSet\": [\n",
    "    #     \"GWP\",\n",
    "    #     \"ODP\",\n",
    "    #     \"POCP\",\n",
    "    #     \"AP\",\n",
    "    #     \"EP\",\n",
    "    #     \"ADPE\",\n",
    "    #     \"ADPF\",\n",
    "    #     \"AP (A2)\",\n",
    "    #     \"GWPtotal (A2)\",\n",
    "    #     \"GWPbiogenic (A2)\",\n",
    "    #     \"GWPfossil (A2)\",\n",
    "    #     \"GWPluluc (A2)\",\n",
    "    #     \"ETPfw (A2)\",\n",
    "    #     \"PM (A2)\",\n",
    "    #     \"EPmarine (A2)\",\n",
    "    #     \"EPfreshwater (A2)\",\n",
    "    #     \"EPterrestrial (A2)\",\n",
    "    #     \"HTPc (A2)\",\n",
    "    #     \"HTPnc (A2)\",\n",
    "    #     \"IRP (A2)\",\n",
    "    #     \"SOP (A2)\",\n",
    "    #     \"ODP (A2)\",\n",
    "    #     \"POCP (A2)\",\n",
    "    #     \"ADPF (A2)\",\n",
    "    #     \"ADPE (A2)\",\n",
    "    #     \"WDP (A2)\",\n",
    "    # ],\n",
    "}\n",
    "\n",
    "# Define JSON schema\n",
    "json_schema = {\n",
    "    \"title\": \"AlignmentResponse\",\n",
    "    \"description\": \"Response containing alignment mappings.\",\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"attribute\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The exact attribute name from dataset A without additional information\",\n",
    "            },\n",
    "            \"match_type\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The type of SKOS match\",\n",
    "                \"enum\": [\"skos:exactMatch\", \"skos:closeMatch\", \"skos:relatedMatch\"],\n",
    "            },\n",
    "            \"field_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The exact 'Field Name (en)' from Schema B without additional information\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"attribute\", \"match_type\", \"field_name\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def query_system(attribute, vectorstore_path, schema_filter):\n",
    "    embeddings = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        vectorstore_path, embeddings=embeddings, allow_dangerous_deserialization=True\n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_kwargs={\"filter\": {\"schema_type\": schema_filter}}\n",
    "    )\n",
    "    retrieved_docs = retriever.invoke(attribute)\n",
    "\n",
    "    if not retrieved_docs:\n",
    "        return None\n",
    "\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "You are an expert in semantic data alignment and ontology matching. Your task is to map the provided attribute from dataset A to its corresponding attribute in Schema B. Use the SKOS relationship types to indicate the alignment:\n",
    "- skos:exactMatch: Attributes are identical in meaning.\n",
    "- skos:closeMatch: Attributes are strongly similar, differing only in minor details.\n",
    "- skos:relatedMatch: Attributes are conceptually related but not hierarchically or equivalently aligned.\n",
    "\n",
    "Attribute Schema B:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "Match the following attribute from dataset A: '{attribute}' to one and only one attribute from Schema B.\n",
    "\n",
    "Return the response in JSON format adhering to the defined schema:\n",
    "[\n",
    "    {{\n",
    "        \"attribute\": \"string\",\n",
    "        \"match_type\": \"string (one of 'skos:exactMatch', 'skos:closeMatch', 'skos:relatedMatch')\",\n",
    "        \"field_name\": \"string (exact value of 'Field Name (en)' without any additional information)\"\n",
    "    }}\n",
    "]\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    final_prompt = prompt_template.format_prompt(\n",
    "        context=context, attribute=attribute\n",
    "    ).to_string()\n",
    "\n",
    "    # Write the final prompt to a text file\n",
    "    with open(\"../data/prompts/prompts.txt\", \"a\") as prompt_file:\n",
    "        prompt_file.write(f\"Final Prompt for {attribute}:\\n\")\n",
    "        prompt_file.write(final_prompt + \"\\n\")\n",
    "        prompt_file.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "    print(final_prompt)\n",
    "\n",
    "    model = ChatOllama(model=\"llama3.1:8b\")\n",
    "    structured_llm = model.with_structured_output(\n",
    "        json_schema, method=\"json_schema\", include_raw=True\n",
    "    )\n",
    "    raw_response = structured_llm.invoke(final_prompt)\n",
    "\n",
    "    structured_response = raw_response.get(\"parsed\", None)\n",
    "\n",
    "    print(structured_response)\n",
    "    print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "    return structured_response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vectorstore_path = \"../embeddings/bge-m3_faiss_index\"\n",
    "    output_file = \"../data/responses/response.json\"\n",
    "\n",
    "    # Reset the JSON file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump([], file)\n",
    "\n",
    "    all_responses = []\n",
    "\n",
    "    for schema, attributes in attribute_schema_mapping.items():\n",
    "        for attribute in attributes:\n",
    "            response = query_system(attribute, vectorstore_path, schema)\n",
    "            if response:\n",
    "                all_responses.extend(response)\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump(all_responses, file, indent=2)\n",
    "\n",
    "    print(f\"All responses saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Attributes per Schema File at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes: 22\n",
      "Number of retrieved documents: 13\n",
      "Human: \n",
      "You are an expert in semantic data alignment and ontology matching. Your task is to map the provided attributes from dataset A to their corresponding fields in Schema B. Use the SKOS relationship types to indicate the alignment:\n",
      "- skos:exactMatch: Attributes are identical in meaning.\n",
      "- skos:closeMatch: Attributes are strongly similar, differing only in minor details.\n",
      "- skos:relatedMatch: Attributes are conceptually related but not hierarchically or equivalently aligned.\n",
      "\n",
      "Definition Schema B:\n",
      "<headers>\n",
      "'Field Name (de)','Field Name (en)','Element/Attribute Name','Datatype','Definition (de)','Definition (en)','Original ILCD Format Definition'\n",
      "</headers>\n",
      "<context>\n",
      "'Vorhergehende Datensatzversion','Preceding data set version','referenceToPrecedingDataSetVersion','GlobalReferenceType','nan','nan','Last preceding data set, which was replaced by this version. Either a URI of that data set (i.e. an internet address) or its UUID plus version number is given (or both).'\n",
      "'Szenario','Scenario','@epd:scenario','String','Verweis auf die oben definierte ID eines Szenarios (falls definiert), für das dieser Wert gilt.','References ID of a scenario defined above','nan'\n",
      "'Szenario','Scenario','@epd:scenario','String','Verweis auf die oben definierte ID eines Szenarios (falls definiert), für das dieser Wert gilt.','References ID of a scenario defined above','nan'\n",
      "'Registrierungsnummer','Registration number','registrationNumber','String','ID-Nummer der EPD oder des Projekts','ID number of EPD or project','A unique identifying number for this data set issued by the registration authority.'\n",
      "'UUID des Datensatzes','UUID of Process data set','UUID','UUID','UUID des Datensatzes. Zusammen mit der Versionsnummer in \"Datensatzversion\" wird der Datensatz damit eindeutig identifizert','~','Automatically generated Universally Unique Identifier of this data set. Together with the \"Data set version\", the UUID uniquely identifies each data set.'\n",
      "'Eindeutiger Klassenidentifizierer','Unique class identifier','@classId','string','Eindeutiger Identifizierer für die Klasse. Dieser sollte mit der Angabe im Beschreibungsdokument übereinstimmen und kann eine UUID oder ein beliebiger anderer Bezeichner sein.','~','Unique identifier for the class. [Notes: If such identifiers are also defined in the referenced category file, they should be identical. Identifiers can be UUID's, but also other forms are allowed.]'\n",
      "'Datensatzversion','Data set version','dataSetVersion','Version','Versionsnummer des Datensatzes','~','Version number of data set. First two digits refer to major updates, the second two digits to minor revisions and error corrections etc. The third three digits are intended for automatic and internal counting of versions during data set development. Together with the data set's UUID, the \"Data set version\" uniquely identifies each data set.'\n",
      "'Veröffentlichung und Eigentümer','Publication and ownership','publicationAndOwnership','nan','Informationen zur Veröffentlichung und Version des Datensatzes','nan','Information related to publication and version management of the data set including copyright and access restrictions.'\n",
      "'Module','Modules','epd:modules','nan','Optionale Deklaration der einzelnen Module, um diese auf der Seite der generierenden Anwendung mit Produktsystemen verknüpfen zu können. Dies ist nützlich, falls der Datensatz später mit dem Werkzeug, welches zur Generierung benutzt wurde, eingelesen und bearbeitet werden soll.','Optional declaration of modules for storing a reference (ID) to the underlying product model on the generating application side. This is useful if you want to open and edit the dataset later with the tool used to generate it.','nan'\n",
      "'Gliederungsklassen','Classes','@classes','anyURI','URL oder Dateiname der Datei, die alle Klassen dieses Gliederungssystems beschreibt.','~','URL or file name of a file listing all classes of this classification system. [Notes: the referenced file has to be in form of the \"ILCDClassification.xml\" format. If a classification file is specified, the \"class\" entry should correspond to the classes defined in the classification file.]'\n",
      "'Szenarien','Scenarios','epd:scenarios','nan','Deklaration der einzelnen Szenarien. Es können mehrere voneinander unabhängige Gruppen von Szenarien deklariert werden, die durch den optionalen Gruppenbezeichner voneinander unterschieden werden können. Dabei kann jeweils ein Szenario als Standardszenario markiert werden.','Declaration of scenarios. Multiple independent groups of scenarios can be declared, using the optional group identifier for differentiation. Within each group, one scenario can be marked as the default one.','nan'\n",
      "'Herausgeber','Issuer','referenceToRegistrationAuthority','GlobalReferenceType','Kontaktdaten des Herausgebers des Datensatzes (z.B. EPD-Programmbetreiber)','~','\"Contact data set\" of the authority that has registered this data set.'\n",
      "'Permanente Datensatz-URI','Permanent data set URI','permanentDataSetURI','anyURI','URI zum Original dieses Datensatzes','~','URI (i.e. an internet address) of the original of this data set. [Note: This equally globally unique identifier supports users and software tools to identify and retrieve the original version of a data set via the internet or to check for available updates. The URI must not represent an existing WWW address, but it should be unique and point to the data access point, e.g. by combining the data owner's www path with the data set's UUID, e.g. http://www.mycompany.com/lca/processes/50f12420-8855-12db-b606-0900210c9a66.]'\n",
      "</context>\n",
      "\n",
      "Match the following attributes to the data under <context> in Schema B:\n",
      "<attributes>\n",
      "UUID\n",
      "Version\n",
      "Name (de)\n",
      "Name (en)\n",
      "Kategorie (original)\n",
      "Kategorie (en)\n",
      "Konformität\n",
      "Laenderkennung\n",
      "Typ\n",
      "Referenzjahr\n",
      "Gueltig bis\n",
      "URL\n",
      "Declaration owner\n",
      "Veroeffentlicht am\n",
      "Registrierungsnummer\n",
      "Registrierungsstelle\n",
      "UUID des Vorgängers\n",
      "Version des Vorgängers\n",
      "URL des Vorgängers\n",
      "Modul\n",
      "Szenario\n",
      "Szenariobeschreibung\n",
      "</attributes>\n",
      "\n",
      "Return the response in JSON format adhering to the defined schema.\n",
      "\n",
      "[{'attribute': 'UUID', 'match_type': 'skos:exactMatch', 'field_name': 'uuid'}, {'attribute': 'Version', 'match_type': 'skos:exactMatch', 'field_name': 'dataSetVersion'}, {'attribute': 'Name (de)', 'match_type': 'skos:closeMatch', 'field_name': 'Field Name (de)'}, {'attribute': 'Name (en)', 'match_type': 'skos:exactMatch', 'field_name': 'Field Name (en)'}, {'attribute': 'Kategorie (original)', 'match_type': 'skos:relatedMatch', 'field_name': 'registrationNumber'}, {'attribute': 'Kategorie (en)', 'match_type': 'skos:exactMatch', 'field_name': 'Registration number'}, {'attribute': 'Konformität', 'match_type': 'skos:relatedMatch', 'field_name': 'publicationAndOwnership'}, {'attribute': 'Laenderkennung', 'match_type': 'skos:closeMatch', 'field_name': 'referenceToRegistrationAuthority'}, {'attribute': 'Typ', 'match_type': 'skos:relatedMatch', 'field_name': '@epd:scenario'}, {'attribute': 'Referenzjahr', 'match_type': 'skos:closeMatch', 'field_name': 'dataSetVersion'}, {'attribute': 'Gueltig bis', 'match_type': 'skos:relatedMatch', 'field_name': ''}, {'attribute': 'URL', 'match_type': 'skos:closeMatch', 'field_name': 'permanentDataSetURI'}, {'attribute': 'Declaration owner', 'match_type': 'skos:exactMatch', 'field_name': 'referenceToRegistrationAuthority'}, {'attribute': 'Veroeffentlicht am', 'match_type': 'skos:relatedMatch', 'field_name': ''}, {'attribute': 'Registrierungsnummer', 'match_type': 'skos:exactMatch', 'field_name': 'registrationNumber'}, {'attribute': 'Registrierungsstelle', 'match_type': 'skos:closeMatch', 'field_name': ''}, {'attribute': 'UUID des Vorgängers', 'match_type': 'skos:exactMatch', 'field_name': 'referenceToPrecedingDataSetVersion'}, {'attribute': 'Version des Vorgängers', 'match_type': 'skos:closeMatch', 'field_name': ''}, {'attribute': 'URL des Vorgängers', 'match_type': 'skos:relatedMatch', 'field_name': ''}, {'attribute': 'Modul', 'match_type': 'skos:exactMatch', 'field_name': ''}, {'attribute': 'Szenario', 'match_type': 'skos:closeMatch', 'field_name': '@epd:scenario'}, {'attribute': 'Szenariobeschreibung', 'match_type': 'skos:relatedMatch', 'field_name': ''}]\n",
      "--------------------------------------------------\n",
      "\n",
      "All responses saved to ../data/responses/response_ollama_csv.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "# Define attribute-schema mapping\n",
    "attribute_schema_mapping = {\n",
    "    \"EPD_DataSet\": [\n",
    "        \"UUID\",\n",
    "        \"Version\",\n",
    "        \"Name (de)\",\n",
    "        \"Name (en)\",\n",
    "        \"Kategorie (original)\",\n",
    "        \"Kategorie (en)\",\n",
    "        \"Konformität\",\n",
    "        \"Laenderkennung\",\n",
    "        \"Typ\",\n",
    "        \"Referenzjahr\",\n",
    "        \"Gueltig bis\",\n",
    "        \"URL\",\n",
    "        \"Declaration owner\",\n",
    "        \"Veroeffentlicht am\",\n",
    "        \"Registrierungsnummer\",\n",
    "        \"Registrierungsstelle\",\n",
    "        \"UUID des Vorgängers\",\n",
    "        \"Version des Vorgängers\",\n",
    "        \"URL des Vorgängers\",\n",
    "        \"Modul\",\n",
    "        \"Szenario\",\n",
    "        \"Szenariobeschreibung\",\n",
    "    ],\n",
    "    # \"EPD_FlowDataSet\": [\n",
    "    #     \"PERE\",\n",
    "    #     \"PERM\",\n",
    "    #     \"PERT\",\n",
    "    #     \"PENRE\",\n",
    "    #     \"PENRM\",\n",
    "    #     \"PENRT\",\n",
    "    #     \"SM\",\n",
    "    #     \"RSF\",\n",
    "    #     \"NRSF\",\n",
    "    #     \"FW\",\n",
    "    #     \"HWD\",\n",
    "    #     \"NHWD\",\n",
    "    #     \"RWD\",\n",
    "    #     \"CRU\",\n",
    "    #     \"MFR\",\n",
    "    #     \"MER\",\n",
    "    #     \"EEE\",\n",
    "    #     \"EET\",\n",
    "    # ],\n",
    "    # \"ILCD_FlowPropertyDataSet\": [\n",
    "    #     \"Bezugsgroesse\",\n",
    "    #     \"Bezugseinheit\",\n",
    "    #     \"Referenzfluss-UUID\",\n",
    "    #     \"Referenzfluss-Name\",\n",
    "    #     \"Schuettdichte (kg/m3)\",\n",
    "    #     \"Flaechengewicht (kg/m2)\",\n",
    "    #     \"Rohdichte (kg/m3)\",\n",
    "    #     \"Schichtdicke (m)\",\n",
    "    #     \"Ergiebigkeit (m2)\",\n",
    "    #     \"Laengengewicht (kg/m)\",\n",
    "    #     \"Stueckgewicht (kg)\",\n",
    "    #     \"Umrechungsfaktor auf 1kg\",\n",
    "    #     \"biogener Kohlenstoffgehalt in kg\",\n",
    "    #     \"biogener Kohlenstoffgehalt (Verpackung) in kg\",\n",
    "    # ],\n",
    "    # \"ILCD_LCIAMethodDataSet\": [\n",
    "    #     \"GWP\",\n",
    "    #     \"ODP\",\n",
    "    #     \"POCP\",\n",
    "    #     \"AP\",\n",
    "    #     \"EP\",\n",
    "    #     \"ADPE\",\n",
    "    #     \"ADPF\",\n",
    "    #     \"AP (A2)\",\n",
    "    #     \"GWPtotal (A2)\",\n",
    "    #     \"GWPbiogenic (A2)\",\n",
    "    #     \"GWPfossil (A2)\",\n",
    "    #     \"GWPluluc (A2)\",\n",
    "    #     \"ETPfw (A2)\",\n",
    "    #     \"PM (A2)\",\n",
    "    #     \"EPmarine (A2)\",\n",
    "    #     \"EPfreshwater (A2)\",\n",
    "    #     \"EPterrestrial (A2)\",\n",
    "    #     \"HTPc (A2)\",\n",
    "    #     \"HTPnc (A2)\",\n",
    "    #     \"IRP (A2)\",\n",
    "    #     \"SOP (A2)\",\n",
    "    #     \"ODP (A2)\",\n",
    "    #     \"POCP (A2)\",\n",
    "    #     \"ADPF (A2)\",\n",
    "    #     \"ADPE (A2)\",\n",
    "    #     \"WDP (A2)\",\n",
    "    # ],\n",
    "}\n",
    "\n",
    "# Define JSON schema\n",
    "json_schema = {\n",
    "    \"title\": \"AlignmentResponse\",\n",
    "    \"description\": \"Response containing alignment mappings.\",\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"attribute\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The attribute from dataset A without additional information\",\n",
    "            },\n",
    "            \"match_type\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The type of SKOS match\",\n",
    "                \"enum\": [\"skos:exactMatch\", \"skos:closeMatch\", \"skos:relatedMatch\"],\n",
    "            },\n",
    "            \"field_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The exact Field Name (en) from Schema B without additional information\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"attribute\", \"match_type\", \"field_name\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def query_system(attributes, vectorstore_path, schema_filter):\n",
    "    embeddings = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        vectorstore_path, embeddings=embeddings, allow_dangerous_deserialization=True\n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_kwargs={\"filter\": {\"schema_type\": schema_filter}, \"k\": len(attributes)}\n",
    "    )\n",
    "    retrieved_docs = retriever.invoke(\"\\n\".join(attributes))\n",
    "\n",
    "    print(f\"Number of attributes: {len(attributes)}\")\n",
    "    print(f\"Number of retrieved documents: {len(retrieved_docs)}\")\n",
    "\n",
    "    if not retrieved_docs:\n",
    "        return None\n",
    "\n",
    "    context = \"\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "You are an expert in semantic data alignment and ontology matching. Your task is to map the provided attributes from dataset A to their corresponding fields in Schema B. Use the SKOS relationship types to indicate the alignment:\n",
    "- skos:exactMatch: Attributes are identical in meaning.\n",
    "- skos:closeMatch: Attributes are strongly similar, differing only in minor details.\n",
    "- skos:relatedMatch: Attributes are conceptually related but not hierarchically or equivalently aligned.\n",
    "\n",
    "Definition Schema B:\n",
    "<headers>\n",
    "'Field Name (de)','Field Name (en)','Element/Attribute Name','Datatype','Definition (de)','Definition (en)','Original ILCD Format Definition'\n",
    "</headers>\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Match the following attributes to the data under <context> in Schema B:\n",
    "<attributes>\n",
    "{attributes}\n",
    "</attributes>\n",
    "\n",
    "Return the response in JSON format adhering to the defined schema.\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    final_prompt = prompt_template.format_prompt(\n",
    "        context=context, attributes=\"\\n\".join(attributes)\n",
    "    ).to_string()\n",
    "\n",
    "    with open(f\"{ollama_prompts}\", \"a\") as prompt_file:\n",
    "        prompt_file.write(final_prompt + \"\\n\\n\" + (\"-\" * 50) + \"\\n\\n\")\n",
    "\n",
    "    print(final_prompt)\n",
    "\n",
    "    model = ChatOllama(model=\"llama3.1:8b\")\n",
    "    structured_llm = model.with_structured_output(\n",
    "        json_schema, method=\"json_schema\", include_raw=True\n",
    "    )\n",
    "    raw_response = structured_llm.invoke(final_prompt)\n",
    "\n",
    "    structured_response = raw_response.get(\"parsed\", None)\n",
    "\n",
    "    print(structured_response)\n",
    "    print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "    return structured_response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vectorstore_path = \"../embeddings/bge-m3_csv_faiss_index\"\n",
    "    output_file = \"../data/responses/response_ollama_csv.json\"\n",
    "\n",
    "    # Reset the JSON file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump([], file)\n",
    "\n",
    "    # Reset the prompts text file\n",
    "    ollama_prompts = \"../data/prompts/prompts_ollama_csv.txt\"\n",
    "    with open(f\"{ollama_prompts}\", \"w\") as prompt_file:\n",
    "        prompt_file.write(\"\")\n",
    "\n",
    "    all_responses = []\n",
    "\n",
    "    for schema, attributes in attribute_schema_mapping.items():\n",
    "        response = query_system(attributes, vectorstore_path, schema)\n",
    "        if response:\n",
    "            all_responses.extend(response)\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump(all_responses, file, indent=2)\n",
    "\n",
    "    print(f\"All responses saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
