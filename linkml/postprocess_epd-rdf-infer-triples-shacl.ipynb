{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, RDF, RDFS, Literal, BNode, SH\n",
    "from pyshacl import validate\n",
    "\n",
    "# 1) Load data and shapes\n",
    "data_graph = Graph().parse(\n",
    "    \"data/rdf/epd_rdf_instance_datastore_canonical_skos_din_bki.ttl\",\n",
    "    format=\"turtle\",\n",
    ")\n",
    "shapes_graph = Graph().parse(\"data/rdf/concrete_class_shacl_shapes.ttl\", format=\"turtle\")\n",
    "\n",
    "# 2) Run pySHACL (advanced features, rule iteration, and inplace inference)\n",
    "conforms, results_graph, results_text = validate(\n",
    "    data_graph,\n",
    "    shacl_graph=shapes_graph,\n",
    "    advanced=True,\n",
    "    iterate_rules=True,\n",
    "    inference=\"rdfs\",\n",
    "    debug=True,\n",
    "    inplace=True,  # inferred triples are added directly into data_graph\n",
    ")\n",
    "\n",
    "print(\"Conforms?\", conforms)\n",
    "print(\"Results:\\n\", results_text)\n",
    "data_graph_starting = data_graph\n",
    "print(\"Total triples in data_graph_starting:\", len(data_graph_starting))\n",
    "print(\"Total triples in results_graph:\", len(results_graph))\n",
    "\n",
    "# Merge any separately returned inferred triples (if any) into data_graph\n",
    "data_graph += results_graph\n",
    "\n",
    "# 3) Clean-up unwanted triples with a single loop.\n",
    "# Define any polluting subjects you want to remove.\n",
    "polluting_subjects = {RDF.type, RDFS.subPropertyOf}\n",
    "polluting_predicate = {SH.conforms, RDFS.subPropertyOf}\n",
    "polluting_objects = {RDF.Property, RDFS.Resource}\n",
    "# Also, set up the SHACL namespace for later comparisons.\n",
    "SHACL = Namespace(\"http://www.w3.org/ns/shacl#\")\n",
    "\n",
    "for s, p, o in list(data_graph.triples((None, None, None))):\n",
    "    if (isinstance(s, Literal)\n",
    "        or (isinstance(s, BNode) and o == SHACL.ValidationReport)\n",
    "        or (s in polluting_subjects)\n",
    "        or (p in polluting_predicate)\n",
    "        or (o in polluting_objects)\n",
    "    ):\n",
    "        data_graph.remove((s, p, o))\n",
    "\n",
    "# 4) Bind preferred prefix for serialization.\n",
    "CC = Namespace(\"https://example.org/concreteclass/\")\n",
    "data_graph.bind(\"cc\", CC)\n",
    "\n",
    "# 5) Serialize the cleaned-up graph.\n",
    "output_path = \"data/rdf/epd_rdf_instance_datastore_canonical_skos_din_bki_shacl.ttl\"\n",
    "data_graph.serialize(output_path, format=\"turtle\")\n",
    "print(f\"Cleaned graph serialized to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See inferred triples after SHACL processing\n",
    "\n",
    "\n",
    "# Load the original and SHACL-processed graphs\n",
    "g_orig = Graph().parse(\n",
    "    \"data/rdf/epd_rdf_instance_datastore_canonical_skos_din_bki.ttl\",\n",
    "    format=\"turtle\"\n",
    ")\n",
    "g_shacl = Graph().parse(\n",
    "    \"data/rdf/epd_rdf_instance_datastore_canonical_skos_din_bki_shacl.ttl\",\n",
    "    format=\"turtle\"\n",
    ")\n",
    "\n",
    "# Count triples\n",
    "n_orig = len(g_orig)\n",
    "n_shacl = len(g_shacl)\n",
    "\n",
    "# Print comparison\n",
    "print(f\"Original graph triples: {n_orig}\")\n",
    "print(f\"SHACL graph triples:    {n_shacl}\")\n",
    "print(f\"Difference:             {n_shacl - n_orig} extra triples in the SHACL graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See added extra lines after SHACL processing\n",
    "\n",
    "\n",
    "# Load the original and SHACL-processed graphs as text files\n",
    "path_orig  = \"data/rdf/epd_rdf_instance_datastore_canonical_skos_din_bki.ttl\"\n",
    "path_shacl = \"data/rdf/epd_rdf_instance_datastore_canonical_skos_din_bki_shacl.ttl\"\n",
    "\n",
    "with open(path_orig, \"r\", encoding=\"utf-8\") as f:\n",
    "    orig_lines = f.readlines()\n",
    "with open(path_shacl, \"r\", encoding=\"utf-8\") as f:\n",
    "    shacl_lines = f.readlines()\n",
    "\n",
    "\n",
    "def filter_lines(lines):\n",
    "    \"\"\"Filter out blank lines and comments from a list of lines.\"\"\"\n",
    "    return [ln for ln in lines if ln.strip() and not ln.lstrip().startswith(\"#\")]\n",
    "\n",
    "# Filter out blank lines and comments\n",
    "orig_core  = filter_lines(orig_lines)\n",
    "shacl_core = filter_lines(shacl_lines)\n",
    "\n",
    "# Count the total number of lines and the number of non-blank/non-comment lines\n",
    "total_orig  = len(orig_lines)\n",
    "total_shacl = len(shacl_lines)\n",
    "core_orig   = len(orig_core)\n",
    "core_shacl  = len(shacl_core)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total lines in original TTL:          {total_orig}\")\n",
    "print(f\"Total lines in SHACL-generated TTL:   {total_shacl}\")\n",
    "print(f\"Difference: {total_shacl - total_orig} extra lines\\n\")\n",
    "\n",
    "print(f\"Non-blank/non-comment lines originally:        {core_orig}\")\n",
    "print(f\"Non-blank/non-comment lines with SHACL data:   {core_shacl}\")\n",
    "print(f\"Core code difference: {core_shacl - core_orig} new statements\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDFlib\n",
    "\n",
    "from rdflib import Graph, Namespace, RDF, Literal, XSD\n",
    "from rdflib.namespace import SKOS\n",
    "\n",
    "# Namespaces\n",
    "CC = Namespace(\"https://example.org/concreteclass/\")\n",
    "ILCD = Namespace(\"https://example.org/ilcd/\")\n",
    "\n",
    "# Create graph and bind prefixes\n",
    "g = Graph()\n",
    "g.bind(\"cc\", CC)\n",
    "g.bind(\"skos\", SKOS)\n",
    "g.bind(\"ilcd\", ILCD)\n",
    "\n",
    "# 1) Define the SKOS concepts (Strength)\n",
    "g.add((CC.LowStrengthConcrete, RDF.type, SKOS.Concept))\n",
    "g.add((CC.LowStrengthConcrete, SKOS.prefLabel, Literal(\"Low Strength Concrete\", \"en\")))\n",
    "g.add(\n",
    "    (\n",
    "        CC.LowStrengthConcrete,\n",
    "        SKOS.note,\n",
    "        Literal(\"Compressive Strength ≤ 25 MPa (e.g., ≤ C16/20)\", \"en\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "g.add((CC.MediumStrengthConcrete, RDF.type, SKOS.Concept))\n",
    "g.add(\n",
    "    (\n",
    "        CC.MediumStrengthConcrete,\n",
    "        SKOS.prefLabel,\n",
    "        Literal(\"Medium Strength Concrete\", \"en\"),\n",
    "    )\n",
    ")\n",
    "g.add(\n",
    "    (\n",
    "        CC.MediumStrengthConcrete,\n",
    "        SKOS.note,\n",
    "        Literal(\"Compressive Strength 25–40 MPa (e.g., C20/25–C30/37)\", \"en\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "g.add((CC.HighStrengthConcrete, RDF.type, SKOS.Concept))\n",
    "g.add(\n",
    "    (CC.HighStrengthConcrete, SKOS.prefLabel, Literal(\"High Strength Concrete\", \"en\"))\n",
    ")\n",
    "g.add(\n",
    "    (\n",
    "        CC.HighStrengthConcrete,\n",
    "        SKOS.note,\n",
    "        Literal(\"Compressive Strength ≥ 40 MPa (e.g., ≥ C35/45)\", \"en\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2) Define the SKOS concepts (Weight)\n",
    "g.add((CC.LightWeightConcrete, RDF.type, SKOS.Concept))\n",
    "g.add((CC.LightWeightConcrete, SKOS.prefLabel, Literal(\"Light Weight Concrete\", \"en\")))\n",
    "g.add((CC.LightWeightConcrete, SKOS.note, Literal(\"Density 800–2000 kg/m³\", \"en\")))\n",
    "\n",
    "g.add((CC.NormalWeightConcrete, RDF.type, SKOS.Concept))\n",
    "g.add(\n",
    "    (CC.NormalWeightConcrete, SKOS.prefLabel, Literal(\"Normal Weight Concrete\", \"en\"))\n",
    ")\n",
    "g.add((CC.NormalWeightConcrete, SKOS.note, Literal(\"Density 2000–2600 kg/m³\", \"en\")))\n",
    "\n",
    "g.add((CC.HeavyWeightConcrete, RDF.type, SKOS.Concept))\n",
    "g.add((CC.HeavyWeightConcrete, SKOS.prefLabel, Literal(\"Heavy Weight Concrete\", \"en\")))\n",
    "g.add((CC.HeavyWeightConcrete, SKOS.note, Literal(\"Density > 2600 kg/m³\", \"en\")))\n",
    "\n",
    "# 3) Parse existing EPD data\n",
    "g.parse(\n",
    "    \"data/rdf/epd_rdf_instance_datastore_canonical_skos_din_bki.ttl\", format=\"turtle\"\n",
    ")\n",
    "\n",
    "# 4) Classify by compressive strength\n",
    "strength_query = \"\"\"\n",
    "PREFIX ilcd: <https://example.org/ilcd/>\n",
    "SELECT ?epd ?val\n",
    "WHERE {\n",
    "  ?epd a ilcd:ProcessDataSet ;\n",
    "       ilcd:exchanges ?exchanges .\n",
    "  ?exchanges ilcd:exchange ?exchangeEntry .\n",
    "  ?exchangeEntry ilcd:materialProperties ?mp .\n",
    "  ?mp ilcd:name \"compressive strength\" ;\n",
    "      ilcd:value ?strVal .\n",
    "  BIND(xsd:float(?strVal) AS ?val)\n",
    "}\n",
    "\"\"\"\n",
    "strength_results = g.query(strength_query)\n",
    "\n",
    "for row in strength_results:\n",
    "    epd_uri = row[\"epd\"]\n",
    "    cs_val = float(row[\"val\"])\n",
    "\n",
    "    if cs_val < 25:\n",
    "        concept = CC.LowStrengthConcrete\n",
    "    elif cs_val <= 40:\n",
    "        concept = CC.MediumStrengthConcrete\n",
    "    else:\n",
    "        concept = CC.HighStrengthConcrete\n",
    "\n",
    "    g.add((epd_uri, CC.hasStrengthClassification, concept))\n",
    "\n",
    "# 5) Classify by bulk density\n",
    "density_query = \"\"\"\n",
    "PREFIX ilcd: <https://example.org/ilcd/>\n",
    "SELECT ?epd ?val\n",
    "WHERE {\n",
    "  ?epd a ilcd:ProcessDataSet ;\n",
    "       ilcd:exchanges ?exchanges .\n",
    "  ?exchanges ilcd:exchange ?exchangeEntry .\n",
    "  ?exchangeEntry ilcd:materialProperties ?mp .\n",
    "  ?mp ilcd:name \"gross density\" ;\n",
    "      ilcd:value ?denVal .\n",
    "  BIND(xsd:float(?denVal) AS ?val)\n",
    "}\n",
    "\"\"\"\n",
    "density_results = g.query(density_query)\n",
    "\n",
    "for row in density_results:\n",
    "    epd_uri = row[\"epd\"]\n",
    "    bd_val = float(row[\"val\"])\n",
    "\n",
    "    if bd_val < 2000:\n",
    "        concept = CC.LightWeightConcrete\n",
    "    elif bd_val <= 2600:\n",
    "        concept = CC.NormalWeightConcrete\n",
    "    else:\n",
    "        concept = CC.HeavyWeightConcrete\n",
    "\n",
    "    g.add((epd_uri, CC.hasWeightClassification, concept))\n",
    "\n",
    "# 6) Serialize final updated graph\n",
    "g.serialize(\n",
    "    \"data/rdf/epd_rdf_instance_datastore_canonical_skos_din_bki_concrete.ttl\",\n",
    "    format=\"turtle\",\n",
    ")\n",
    "print(\n",
    "    \"Classification complete. Output saved to epd_rdf_instance_datastore_canonical_skos_din_bki_concrete.ttl\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate data by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase by duplicating instance data in an RDF graph by 10x\n",
    "\n",
    "from rdflib import Graph, URIRef, RDF\n",
    "from pathlib import Path\n",
    "\n",
    "SRC_FILE = \"data/rdf/epd_rdf_instance_datastore_canonical_skos_din_bki_shacl.ttl\"\n",
    "DST_FILE = \"data/rdf/epd_scaled_x10.ttl\"\n",
    "COPIES   = 9   # original + 9 duplicates = 10×\n",
    "\n",
    "# Parse the original graph\n",
    "g = Graph()\n",
    "g.parse(SRC_FILE, format=\"turtle\")\n",
    "print(f\"Original graph size: {len(g):,} triples\")\n",
    "\n",
    "# Identify namespaces that hold instance data\n",
    "PREFIXES_TO_SCALE = [\"ilcd\", \"obd\", \"cc\", \"din\", \"bki\"]\n",
    "namespaces = {\n",
    "    prefix: str(uri)\n",
    "    for prefix, uri in g.namespace_manager.namespaces()\n",
    "    if prefix in PREFIXES_TO_SCALE\n",
    "}\n",
    "print(\"Duplicate instances in these namespaces →\")\n",
    "for prefix, ns in namespaces.items():\n",
    "    print(f\"  {prefix}: {ns}\")\n",
    "\n",
    "# Collect every URIRef that appears as a subject in one of those namespaces\n",
    "instance_nodes = {\n",
    "    s for s, _, _ in g\n",
    "    if isinstance(s, URIRef)\n",
    "    and any(str(s).startswith(ns) for ns in namespaces.values())\n",
    "}\n",
    "\n",
    "# Duplicate each matching triple for every copy\n",
    "new_triples = []\n",
    "for copy_idx in range(1, COPIES + 1):\n",
    "    suffix  = f\"_copy{copy_idx}\"\n",
    "    mapping = {uri: URIRef(str(uri) + suffix) for uri in instance_nodes}\n",
    "    for s, p, o in g:\n",
    "        # Rename subject if it is an instance we are copying\n",
    "        s2 = mapping.get(s, s)\n",
    "        # Rename object only if **that object is itself being duplicated**.\n",
    "        # All class URIs stay unchanged, so queries remain valid.\n",
    "        o2 = mapping.get(o, o)\n",
    "        if (s2, p, o2) != (s, p, o):\n",
    "            new_triples.append((s2, p, o2))\n",
    "    print(f\"Completed copy {copy_idx}\")\n",
    "\n",
    "# Create the scaled graph and bind original prefixes\n",
    "scaled = Graph()\n",
    "for prefix, ns in g.namespace_manager.namespaces():\n",
    "    scaled.bind(prefix, ns, replace=True)\n",
    "\n",
    "# Add original triples and the duplicates\n",
    "scaled += g\n",
    "try:\n",
    "    scaled.addN((s, p, o, scaled) for s, p, o in new_triples)\n",
    "except AttributeError:                     # rdflib <6.0\n",
    "    for triple in new_triples:\n",
    "        scaled.add(triple)\n",
    "\n",
    "print(f\"Scaled graph size: {len(scaled):,} triples\")\n",
    "\n",
    "# Serialize the scaled graph to Turtle, preserving prefixes\n",
    "Path(DST_FILE).parent.mkdir(parents=True, exist_ok=True)\n",
    "scaled.serialize(DST_FILE, format=\"turtle\")\n",
    "print(f\"Wrote: {DST_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
