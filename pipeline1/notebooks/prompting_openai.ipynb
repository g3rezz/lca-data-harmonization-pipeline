{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4o-mini"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load OpenAI API key from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "# Define attribute-schema mapping\n",
    "attribute_schema_mapping = {\n",
    "    \"EPD_DataSet\": [\n",
    "        \"UUID\",\n",
    "        \"Version\",\n",
    "        \"Name (de)\",\n",
    "        \"Name (en)\",\n",
    "        \"Kategorie (original)\",\n",
    "        \"Kategorie (en)\",\n",
    "        \"Konformit채t\",\n",
    "        \"Laenderkennung\",\n",
    "        \"Typ\",\n",
    "        \"Referenzjahr\",\n",
    "        \"Gueltig bis\",\n",
    "        \"URL\",\n",
    "        \"Declaration owner\",\n",
    "        \"Veroeffentlicht am\",\n",
    "        \"Registrierungsnummer\",\n",
    "        \"Registrierungsstelle\",\n",
    "        \"UUID des Vorg채ngers\",\n",
    "        \"Version des Vorg채ngers\",\n",
    "        \"URL des Vorg채ngers\",\n",
    "        \"Modul\",\n",
    "        \"Szenario\",\n",
    "        \"Szenariobeschreibung\",\n",
    "    ],\n",
    "    \"EPD_FlowDataSet\": [\n",
    "        \"PERE\",\n",
    "        \"PERM\",\n",
    "        \"PERT\",\n",
    "        \"PENRE\",\n",
    "        \"PENRM\",\n",
    "        \"PENRT\",\n",
    "        \"SM\",\n",
    "        \"RSF\",\n",
    "        \"NRSF\",\n",
    "        \"FW\",\n",
    "        \"HWD\",\n",
    "        \"NHWD\",\n",
    "        \"RWD\",\n",
    "        \"CRU\",\n",
    "        \"MFR\",\n",
    "        \"MER\",\n",
    "        \"EEE\",\n",
    "        \"EET\",\n",
    "    ],\n",
    "    \"ILCD_FlowPropertyDataSet\": [\n",
    "        \"Bezugsgroesse\",\n",
    "        \"Bezugseinheit\",\n",
    "        \"Referenzfluss-UUID\",\n",
    "        \"Referenzfluss-Name\",\n",
    "        \"Schuettdichte (kg/m3)\",\n",
    "        \"Flaechengewicht (kg/m2)\",\n",
    "        \"Rohdichte (kg/m3)\",\n",
    "        \"Schichtdicke (m)\",\n",
    "        \"Ergiebigkeit (m2)\",\n",
    "        \"Laengengewicht (kg/m)\",\n",
    "        \"Stueckgewicht (kg)\",\n",
    "        \"Umrechungsfaktor auf 1kg\",\n",
    "        \"biogener Kohlenstoffgehalt in kg\",\n",
    "        \"biogener Kohlenstoffgehalt (Verpackung) in kg\",\n",
    "    ],\n",
    "    \"ILCD_LCIAMethodDataSet\": [\n",
    "        \"GWP\",\n",
    "        \"ODP\",\n",
    "        \"POCP\",\n",
    "        \"AP\",\n",
    "        \"EP\",\n",
    "        \"ADPE\",\n",
    "        \"ADPF\",\n",
    "        \"AP (A2)\",\n",
    "        \"GWPtotal (A2)\",\n",
    "        \"GWPbiogenic (A2)\",\n",
    "        \"GWPfossil (A2)\",\n",
    "        \"GWPluluc (A2)\",\n",
    "        \"ETPfw (A2)\",\n",
    "        \"PM (A2)\",\n",
    "        \"EPmarine (A2)\",\n",
    "        \"EPfreshwater (A2)\",\n",
    "        \"EPterrestrial (A2)\",\n",
    "        \"HTPc (A2)\",\n",
    "        \"HTPnc (A2)\",\n",
    "        \"IRP (A2)\",\n",
    "        \"SOP (A2)\",\n",
    "        \"ODP (A2)\",\n",
    "        \"POCP (A2)\",\n",
    "        \"ADPF (A2)\",\n",
    "        \"ADPE (A2)\",\n",
    "        \"WDP (A2)\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Define JSON schema\n",
    "json_schema = {\n",
    "    \"title\": \"AlignmentResponse\",\n",
    "    \"description\": \"Response containing alignment mappings.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"mappings\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"attribute\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The attribute from dataset A without additional information\",\n",
    "                    },\n",
    "                    \"match_type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The type of SKOS match\",\n",
    "                        \"enum\": [\n",
    "                            \"skos:exactMatch\",\n",
    "                            \"skos:closeMatch\",\n",
    "                            \"skos:relatedMatch\",\n",
    "                        ],\n",
    "                    },\n",
    "                    \"field_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The exact Field Name (en) from Schema B without additional information\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"attribute\", \"match_type\", \"field_name\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"mappings\"],\n",
    "}\n",
    "\n",
    "\n",
    "def query_system(attributes, vectorstore_path, schema_filter):\n",
    "    embeddings = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        vectorstore_path, embeddings=embeddings, allow_dangerous_deserialization=True\n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_kwargs={\"filter\": {\"schema_type\": schema_filter}, \"k\": len(attributes)}\n",
    "    )\n",
    "    retrieved_docs = retriever.invoke(\"\\n\".join(attributes))\n",
    "\n",
    "    print(f\"Number of attributes: {len(attributes)}\")\n",
    "\n",
    "    num_retrieved_docs = len(retrieved_docs)\n",
    "    print(f\"Number of retrieved documents: {num_retrieved_docs}\")\n",
    "\n",
    "    if not retrieved_docs:\n",
    "        return None\n",
    "\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "You are an expert in semantic data alignment and ontology matching. Your task is to map the provided attributes from dataset A to their corresponding fields in Schema B. Use the SKOS relationship types to indicate the alignment:\n",
    "- skos:exactMatch: Attributes are identical in meaning.\n",
    "- skos:closeMatch: Attributes are strongly similar, differing only in minor details.\n",
    "- skos:relatedMatch: Attributes are conceptually related but not hierarchically or equivalently aligned.\n",
    "\n",
    "Attribute Schema B:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "Match the following attributes to Schema B:\n",
    "<attributes>\n",
    "{attributes}\n",
    "</attributes>\n",
    "Return the response in JSON format adhering to the defined schema.\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    final_prompt = prompt_template.format_prompt(\n",
    "        context=context, attributes=\"\\n\".join(attributes)\n",
    "    ).to_string()\n",
    "\n",
    "    with open(f\"../data/prompts_{model}.txt\", \"a\") as prompt_file:\n",
    "        prompt_file.write(final_prompt + \"\\n\\n\" + (\"-\" * 50) + \"\\n\\n\")\n",
    "\n",
    "    print(final_prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an assistant that returns structured outputs in JSON format.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": final_prompt},\n",
    "        ],\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"generate_response\",\n",
    "                \"description\": \"Generates structured alignment mappings.\",\n",
    "                \"parameters\": json_schema,\n",
    "            }\n",
    "        ],\n",
    "        function_call=\"auto\",\n",
    "    )\n",
    "\n",
    "    structured_response = json.loads(\n",
    "        response.choices[0].message.function_call.arguments\n",
    "    )[\"mappings\"]\n",
    "\n",
    "    print(structured_response)\n",
    "    print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "    return structured_response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vectorstore_path = \"../embeddings/bge-m3_faiss_index\"\n",
    "    output_file = f\"../data/response_{model}.json\"\n",
    "\n",
    "    # Reset the JSON file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump([], file)\n",
    "\n",
    "    # Reset the prompts text file\n",
    "    with open(f\"../data/prompts_{model}.txt\", \"w\") as prompt_file:\n",
    "        prompt_file.write(\"\")\n",
    "\n",
    "    all_responses = []\n",
    "\n",
    "    for schema, attributes in attribute_schema_mapping.items():\n",
    "        response = query_system(attributes, vectorstore_path, schema)\n",
    "        if response:\n",
    "            all_responses.extend(response)\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump(all_responses, file, indent=2)\n",
    "\n",
    "    print(f\"All responses saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
